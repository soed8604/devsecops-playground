"use strict";(self.webpackChunkes_documentacion_devops=self.webpackChunkes_documentacion_devops||[]).push([[4346],{6190:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>i,contentTitle:()=>c,default:()=>u,frontMatter:()=>d,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"kubernetes/troubleshooting/dashboard-api-crashloop","title":"Dashboard API Pod en CrashLoopBackOff","description":"S\xedntoma","source":"@site/docs/kubernetes/troubleshooting/07-dashboard-api-crashloop.md","sourceDirName":"kubernetes/troubleshooting","slug":"/kubernetes/troubleshooting/dashboard-api-crashloop","permalink":"/devsecops-playground/docs/kubernetes/troubleshooting/dashboard-api-crashloop","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/kubernetes/troubleshooting/07-dashboard-api-crashloop.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Dashboard API Pod en CrashLoopBackOff"},"sidebar":"tutorialSidebar","previous":{"title":"Calico: BGP Peering No Establecido (Puerto 179)","permalink":"/devsecops-playground/docs/kubernetes/troubleshooting/calico-bgp-not-established"},"next":{"title":"Pre-requisitos del Sistema","permalink":"/devsecops-playground/docs/kubernetes/instalacion/prerequisitos"}}');var s=n(4848),r=n(8453);const d={sidebar_position:7,title:"Dashboard API Pod en CrashLoopBackOff"},c="Problema: Dashboard API Pod en CrashLoopBackOff",i={},l=[{value:"S\xedntoma",id:"s\xedntoma",level:2},{value:"Diagn\xf3stico",id:"diagn\xf3stico",level:2},{value:"Causa Ra\xedz",id:"causa-ra\xedz",level:2},{value:"Soluci\xf3n",id:"soluci\xf3n",level:2},{value:"Verificaci\xf3n",id:"verificaci\xf3n",level:2}];function t(e){const o={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(o.header,{children:(0,s.jsx)(o.h1,{id:"problema-dashboard-api-pod-en-crashloopbackoff",children:"Problema: Dashboard API Pod en CrashLoopBackOff"})}),"\n",(0,s.jsx)(o.h2,{id:"s\xedntoma",children:"S\xedntoma"}),"\n",(0,s.jsxs)(o.p,{children:["Despu\xe9s de instalar el Kubernetes Dashboard con Helm, el pod ",(0,s.jsx)(o.code,{children:"kubernetes-dashboard-api-..."})," en el namespace ",(0,s.jsx)(o.code,{children:"kubernetes-dashboard"})," se queda en estado ",(0,s.jsx)(o.code,{children:"CrashLoopBackOff"}),". Otros pods del Dashboard (auth, web, scraper) pueden estar ",(0,s.jsx)(o.code,{children:"Running"}),"."]}),"\n",(0,s.jsx)(o.pre,{children:(0,s.jsx)(o.code,{className:"language-bash",children:"kubectl get pods -n kubernetes-dashboard\n"})}),"\n",(0,s.jsx)(o.h2,{id:"diagn\xf3stico",children:"Diagn\xf3stico"}),"\n",(0,s.jsx)(o.p,{children:"El estado CrashLoopBackOff significa que el contenedor principal dentro del pod arranca y se cierra repetidamente. Revisando los logs del pod se encuentra un error de conexi\xf3n."}),"\n",(0,s.jsx)(o.pre,{children:(0,s.jsx)(o.code,{className:"language-bash",children:"kubectl logs kubernetes-dashboard-api-<HASH> -n kubernetes-dashboard\n"})}),"\n",(0,s.jsxs)(o.p,{children:["El log muestra un ",(0,s.jsx)(o.code,{children:"i/o timeout"})," al intentar conectar a ",(0,s.jsx)(o.code,{children:"10.96.0.1:443"}),". Esta es la IP y puerto del servicio ClusterIP del API Server de Kubernetes (",(0,s.jsx)(o.code,{children:"kubernetes.default.svc.cluster.local"}),"). El pod del Dashboard API, al estar dentro del cluster, intenta comunicarse con el API Server usando esta direcci\xf3n interna."]}),"\n",(0,s.jsx)(o.h2,{id:"causa-ra\xedz",children:"Causa Ra\xedz"}),"\n",(0,s.jsxs)(o.p,{children:["El ",(0,s.jsx)(o.code,{children:"timeout"})," al intentar conectar al ClusterIP del API Server desde un pod (el del Dashboard API) indica que la red de pods en el nodo donde corre ese pod no est\xe1 funcionando correctamente o no puede alcanzar el servicio del API Server."]}),"\n",(0,s.jsxs)(o.p,{children:["En nuestro caso, el pod del Dashboard API estaba corriendo en ",(0,s.jsx)(o.code,{children:"k8s-worker-X"}),", y el problema era que el agente de red de Calico (",(0,s.jsx)(o.code,{children:"calico-node"}),") en ",(0,s.jsx)(o.code,{children:"k8s-worker-X"})," no estaba Ready (0/1). Si la CNI no est\xe1 Ready en un nodo, la red para los pods en ese nodo no funciona, impidiendo la comunicaci\xf3n interna del cluster, incluyendo el acceso a ClusterIPs."]}),"\n",(0,s.jsx)(o.h2,{id:"soluci\xf3n",children:"Soluci\xf3n"}),"\n",(0,s.jsxs)(o.p,{children:["Resolver los problemas subyacentes que impiden que el agente de red de Calico (",(0,s.jsx)(o.code,{children:"calico-node"}),") pase a estado ",(0,s.jsx)(o.code,{children:"READY"})," en el nodo donde corre el pod del Dashboard API."]}),"\n",(0,s.jsxs)(o.p,{children:["Las causas comunes de que ",(0,s.jsx)(o.code,{children:"calico-node"})," no est\xe9 Ready (0/1) se documentan en detalle en otras secciones de Troubleshooting:"]}),"\n",(0,s.jsxs)(o.ul,{children:["\n",(0,s.jsx)(o.li,{children:(0,s.jsx)(o.a,{href:"/docs/kubernetes/troubleshooting/03-calico-node-notready-overview",children:"Overview del Problema Calico 0/1 Ready"})}),"\n",(0,s.jsx)(o.li,{children:(0,s.jsx)(o.a,{href:"/docs/kubernetes/troubleshooting/04-calico-missing-bird-config",children:"Calico: BIRD no encuentra archivos de configuraci\xf3n"})}),"\n",(0,s.jsx)(o.li,{children:(0,s.jsx)(o.a,{href:"/docs/kubernetes/troubleshooting/05-calico-typha-timeout",children:"Calico: Fallo al conectar a Typha (Timeout 5473)"})}),"\n",(0,s.jsx)(o.li,{children:(0,s.jsx)(o.a,{href:"/docs/kubernetes/troubleshooting/06-calico-bgp-not-established",children:"Calico: BGP Peering No Establecido (Puerto 179)"})}),"\n"]}),"\n",(0,s.jsxs)(o.p,{children:["Una vez que hayas solucionado el problema espec\xedfico que imped\xeda a ",(0,s.jsx)(o.code,{children:"calico-node"})," estar ",(0,s.jsx)(o.code,{children:"READY"})," en el nodo worker (probablemente un problema de firewall con el puerto 179 o 5473, o un problema con el pod Typha), la red en ese nodo se corregir\xe1, el pod ",(0,s.jsx)(o.code,{children:"kubernetes-dashboard-api"})," podr\xe1 conectar al API Server a trav\xe9s de su ClusterIP, y pasar\xe1 a estado ",(0,s.jsx)(o.code,{children:"Running"})," (1/1 Ready)."]}),"\n",(0,s.jsx)(o.h2,{id:"verificaci\xf3n",children:"Verificaci\xf3n"}),"\n",(0,s.jsx)(o.p,{children:"Verifica el estado de los pods del Dashboard nuevamente."}),"\n",(0,s.jsx)(o.pre,{children:(0,s.jsx)(o.code,{className:"language-bash",children:"kubectl get pods -n kubernetes-dashboard\n"})}),"\n",(0,s.jsxs)(o.p,{children:["Una vez que todos los pods del Dashboard est\xe9n ",(0,s.jsx)(o.code,{children:"Running"})," y ",(0,s.jsx)(o.code,{children:"Ready"}),", podr\xe1s acceder a la interfaz web (ver secci\xf3n de Acceso)."]})]})}function u(e={}){const{wrapper:o}={...(0,r.R)(),...e.components};return o?(0,s.jsx)(o,{...e,children:(0,s.jsx)(t,{...e})}):t(e)}},8453:(e,o,n)=>{n.d(o,{R:()=>d,x:()=>c});var a=n(6540);const s={},r=a.createContext(s);function d(e){const o=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function c(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),a.createElement(r.Provider,{value:o},e.children)}}}]);